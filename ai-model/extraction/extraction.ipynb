{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Users\\Public\\Documents\\CulinaCraft\\ai-model\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "from transformers import pipeline\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def parse_ingredient_list(ingredient_string):\n",
    "    \"\"\"Convert a string representation of a list into an actual Python list.\"\"\"\n",
    "    return json.loads(ingredient_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Available: True\n",
      "CUDA Device: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resep_df = pd.read_csv('../dataset/dataset-resep/recipes_sample.csv')\n",
    "resep_df = resep_df.drop(columns=['link', 'source', 'site'])\n",
    "resep_df['ingredients'] = resep_df['ingredients'].apply(parse_ingredient_list)\n",
    "resep_df['directions'] = resep_df['directions'].apply(parse_ingredient_list)\n",
    "resep_df['NER'] = resep_df['NER'].apply(parse_ingredient_list)\n",
    "resep_df = resep_df.drop(columns=['title', 'directions'])\n",
    "# Keep only rows where len(ingredients) == len(NER)\n",
    "resep_df = resep_df[resep_df['ingredients'].apply(len) == resep_df['NER'].apply(len)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_ner_by_similarity(ingredients, ner_list):\n",
    "    \"\"\"\n",
    "    Sorts the NER list to align with the ingredients list using TF-IDF and cosine similarity.\n",
    "\n",
    "    Parameters:\n",
    "    - ingredients: List of ingredient descriptions.\n",
    "    - ner_list: List of Named Entity Recognitions (NER).\n",
    "\n",
    "    Returns:\n",
    "    - Sorted NER list matching the order of ingredients.\n",
    "    \"\"\"\n",
    "    if len(ingredients) != len(ner_list):\n",
    "        return None  # Return None if lengths do not match\n",
    "\n",
    "    # Initialize TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Compute TF-IDF for both lists\n",
    "    tfidf_matrix = vectorizer.fit_transform(ingredients + ner_list)\n",
    "\n",
    "    # Split the TF-IDF matrix\n",
    "    tfidf_ingredients = tfidf_matrix[:len(ingredients)]\n",
    "    tfidf_ner = tfidf_matrix[len(ingredients):]\n",
    "\n",
    "    # Compute cosine similarity between each ingredient and all NER labels\n",
    "    similarity_matrix = cosine_similarity(tfidf_ingredients, tfidf_ner)\n",
    "\n",
    "    # Find the best matching NER for each ingredient\n",
    "    sorted_ner = []\n",
    "    used_indices = set()\n",
    "\n",
    "    for i in range(len(ingredients)):\n",
    "        # Find the best match that hasn't been used yet\n",
    "        best_match_idx = np.argmax(similarity_matrix[i])\n",
    "        while best_match_idx in used_indices:\n",
    "            similarity_matrix[i][best_match_idx] = -1  # Ignore already used matches\n",
    "            best_match_idx = np.argmax(similarity_matrix[i])\n",
    "        \n",
    "        sorted_ner.append(ner_list[best_match_idx])\n",
    "        used_indices.add(best_match_idx)\n",
    "\n",
    "    return sorted_ner\n",
    "\n",
    "# Apply the function to each row of the dataframe\n",
    "resep_df['NER'] = resep_df.apply(lambda row: sort_ner_by_similarity(row['ingredients'], row['NER']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 1/2 pound flank steak, 1/2 c. finely minced...</td>\n",
       "      <td>[flank steak, green onions, red wine, soy sauc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3 to 4 carrots, 1 1/2 Tbsp. butter, 1/3 c. br...</td>\n",
       "      <td>[carrots, butter, brown sugar, lemon rind]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4.5 Cups Flour, 1.5 Tsp Salt, Pinch Baking Po...</td>\n",
       "      <td>[flour, salt, baking powder, sugar, crisco, eg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2 c. crushed small thin pretzels (sticks), 3/...</td>\n",
       "      <td>[thin pretzels, margarine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3/4 cup sugar, 1/2 cup fresh orange juice, 1/...</td>\n",
       "      <td>[sugar, orange juice, lemon juice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6975</th>\n",
       "      <td>[1 (6 ounce) package STOVE TOP Stuffing Mix fo...</td>\n",
       "      <td>[stove, turkey, carrots, mayonnaise, leftover ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6976</th>\n",
       "      <td>[3 cups rolled oats, 3/4 cup fresh orange juic...</td>\n",
       "      <td>[rolled oats, fresh orange juice, milk, sugar,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6977</th>\n",
       "      <td>[4 summer squash, 2 cups orange marmalade, 1 c...</td>\n",
       "      <td>[summer, orange marmalade, shredded coconut, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6978</th>\n",
       "      <td>[2 medium butternut squash baked and cut into ...</td>\n",
       "      <td>[butternut, russet potatoes, fingerling potato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6979</th>\n",
       "      <td>[2 lb. pork, cubed, 2 Tbsp. vinegar, 1 c. onio...</td>\n",
       "      <td>[pork, vinegar, onion, garlic, tomato, parsley...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6980 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ingredients  \\\n",
       "0     [1 1/2 pound flank steak, 1/2 c. finely minced...   \n",
       "1     [3 to 4 carrots, 1 1/2 Tbsp. butter, 1/3 c. br...   \n",
       "2     [4.5 Cups Flour, 1.5 Tsp Salt, Pinch Baking Po...   \n",
       "3     [2 c. crushed small thin pretzels (sticks), 3/...   \n",
       "4     [3/4 cup sugar, 1/2 cup fresh orange juice, 1/...   \n",
       "...                                                 ...   \n",
       "6975  [1 (6 ounce) package STOVE TOP Stuffing Mix fo...   \n",
       "6976  [3 cups rolled oats, 3/4 cup fresh orange juic...   \n",
       "6977  [4 summer squash, 2 cups orange marmalade, 1 c...   \n",
       "6978  [2 medium butternut squash baked and cut into ...   \n",
       "6979  [2 lb. pork, cubed, 2 Tbsp. vinegar, 1 c. onio...   \n",
       "\n",
       "                                                    NER  \n",
       "0     [flank steak, green onions, red wine, soy sauc...  \n",
       "1            [carrots, butter, brown sugar, lemon rind]  \n",
       "2     [flour, salt, baking powder, sugar, crisco, eg...  \n",
       "3                            [thin pretzels, margarine]  \n",
       "4                    [sugar, orange juice, lemon juice]  \n",
       "...                                                 ...  \n",
       "6975  [stove, turkey, carrots, mayonnaise, leftover ...  \n",
       "6976  [rolled oats, fresh orange juice, milk, sugar,...  \n",
       "6977  [summer, orange marmalade, shredded coconut, m...  \n",
       "6978  [butternut, russet potatoes, fingerling potato...  \n",
       "6979  [pork, vinegar, onion, garlic, tomato, parsley...  \n",
       "\n",
       "[6980 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 1/2 pound flank steak</td>\n",
       "      <td>flank steak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2 c. finely minced green onions (scallions)</td>\n",
       "      <td>green onions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/2 c. dry red wine</td>\n",
       "      <td>red wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/4 c. soy sauce</td>\n",
       "      <td>soy sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 tbsp. salad oil</td>\n",
       "      <td>salad oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55013</th>\n",
       "      <td>1/2 c. chopped celery</td>\n",
       "      <td>celery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55014</th>\n",
       "      <td>1 tsp. salt</td>\n",
       "      <td>salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55015</th>\n",
       "      <td>1 tsp. black pepper</td>\n",
       "      <td>black pepper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55016</th>\n",
       "      <td>1/2 c. cooking oil</td>\n",
       "      <td>cooking oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55017</th>\n",
       "      <td>3 c. hot water</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55018 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ingredients           NER\n",
       "0                            1 1/2 pound flank steak   flank steak\n",
       "1      1/2 c. finely minced green onions (scallions)  green onions\n",
       "2                                1/2 c. dry red wine      red wine\n",
       "3                                   1/4 c. soy sauce     soy sauce\n",
       "4                                  3 tbsp. salad oil     salad oil\n",
       "...                                              ...           ...\n",
       "55013                          1/2 c. chopped celery        celery\n",
       "55014                                    1 tsp. salt          salt\n",
       "55015                            1 tsp. black pepper  black pepper\n",
       "55016                             1/2 c. cooking oil   cooking oil\n",
       "55017                                 3 c. hot water         water\n",
       "\n",
       "[55018 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def explode_ingredients(df):\n",
    "    \"\"\"\n",
    "    Transforms the dataset so that each row contains only one ingredient and its corresponding NER tag.\n",
    "    \"\"\"\n",
    "    # Create a new dataframe by exploding the ingredients and NER columns\n",
    "    df_exploded = df.explode([\"ingredients\", \"NER\"], ignore_index=True)\n",
    "    \n",
    "    return df_exploded\n",
    "\n",
    "# Apply the function to transform the dataset\n",
    "resep_df = explode_ingredients(resep_df)\n",
    "\n",
    "# Display the first few rows of the transformed dataframe\n",
    "resep_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "resep_df.to_csv('resep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/distilbert-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/distilbert-NER\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 1/2 pound flank steak</td>\n",
       "      <td>flank steak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2 c. finely minced green onions (scallions)</td>\n",
       "      <td>green onions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/2 c. dry red wine</td>\n",
       "      <td>red wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/4 c. soy sauce</td>\n",
       "      <td>soy sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 tbsp. salad oil</td>\n",
       "      <td>salad oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55013</th>\n",
       "      <td>1/2 c. chopped celery</td>\n",
       "      <td>celery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55014</th>\n",
       "      <td>1 tsp. salt</td>\n",
       "      <td>salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55015</th>\n",
       "      <td>1 tsp. black pepper</td>\n",
       "      <td>black pepper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55016</th>\n",
       "      <td>1/2 c. cooking oil</td>\n",
       "      <td>cooking oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55017</th>\n",
       "      <td>3 c. hot water</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55018 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ingredients           NER\n",
       "0                            1 1/2 pound flank steak   flank steak\n",
       "1      1/2 c. finely minced green onions (scallions)  green onions\n",
       "2                                1/2 c. dry red wine      red wine\n",
       "3                                   1/4 c. soy sauce     soy sauce\n",
       "4                                  3 tbsp. salad oil     salad oil\n",
       "...                                              ...           ...\n",
       "55013                          1/2 c. chopped celery        celery\n",
       "55014                                    1 tsp. salt          salt\n",
       "55015                            1 tsp. black pepper  black pepper\n",
       "55016                             1/2 c. cooking oil   cooking oil\n",
       "55017                                 3 c. hot water         water\n",
       "\n",
       "[55018 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55018/55018 [00:06<00:00, 8468.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def tokenize_ner(examples):\n",
    "    \"\"\"\n",
    "    Tokenizes the ingredients text and labels NER tokens.\n",
    "    \n",
    "    Args:\n",
    "    examples (dict): A batch of examples containing 'ingredients' and 'NER'.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with input_ids, attention_mask, and labels.\n",
    "    \"\"\"\n",
    "    texts = examples[\"ingredients\"]\n",
    "    ner_entities = examples[\"NER\"]\n",
    "    \n",
    "    # Tokenize the batch of texts\n",
    "    encodings = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    \n",
    "    labels_batch = []\n",
    "    \n",
    "    for text, ner_entity, input_ids in zip(texts, ner_entities, encodings[\"input_ids\"]):\n",
    "        # Initialize labels with 0 (non-NER)\n",
    "        labels = [0] * len(input_ids)\n",
    "        \n",
    "        # Tokenize the NER entity separately\n",
    "        ner_tokens = tokenizer.tokenize(ner_entity)\n",
    "        \n",
    "        # Tokenize the full text\n",
    "        input_tokens = tokenizer.tokenize(text)\n",
    "        \n",
    "        # Find and mark NER tokens\n",
    "        for i in range(len(input_tokens) - len(ner_tokens) + 1):\n",
    "            if input_tokens[i : i + len(ner_tokens)] == ner_tokens:\n",
    "                token_start = i + 1  # Adjust for [CLS] token at the start\n",
    "                for j in range(len(ner_tokens)):\n",
    "                    labels[token_start + j] = 1  # Mark as NER\n",
    "                break\n",
    "        \n",
    "        labels_batch.append(labels)\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": encodings[\"input_ids\"].tolist(),\n",
    "        \"attention_mask\": encodings[\"attention_mask\"].tolist(),\n",
    "        \"labels\": labels_batch\n",
    "    }\n",
    "\n",
    "# Convert DataFrame to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(resep_df)\n",
    "\n",
    "# Process dataset and remove unused columns\n",
    "dataset = dataset.map(tokenize_ner, batched=True, remove_columns=[\"ingredients\", \"NER\"])\n",
    "\n",
    "# Split dataset into train and test\n",
    "train_test_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 124, 6471, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print((train_dataset['input_ids'][0]))\n",
    "print((train_dataset['attention_mask'][0]))\n",
    "print((train_dataset['labels'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Users\\Public\\Documents\\CulinaCraft\\ai-model\\.venv\\lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15012\\429462773.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4128' max='4128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4128/4128 06:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.003521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4128, training_loss=0.02516202608036787, metrics={'train_runtime': 419.625, 'train_samples_per_second': 314.667, 'train_steps_per_second': 9.837, 'total_flos': 4313470039248384.0, 'train_loss': 0.02516202608036787, 'epoch': 3.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    fp16=True,\n",
    "    output_dir=\"./ner_finetuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./ner_finetuned\\\\tokenizer_config.json',\n",
       " './ner_finetuned\\\\special_tokens_map.json',\n",
       " './ner_finetuned\\\\vocab.txt',\n",
       " './ner_finetuned\\\\added_tokens.json',\n",
       " './ner_finetuned\\\\tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./ner_finetuned\")\n",
    "tokenizer.save_pretrained(\"./ner_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_path = \"./ner_finetuned\"  # Path where the trained model is saved\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Create an NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: green, Label: PER, Score: 0.9989\n",
      "Entity: meat, Label: PER, Score: 0.9989\n"
     ]
    }
   ],
   "source": [
    "# Example input string\n",
    "ingredient_text = \"green meat\"\n",
    "\n",
    "# Get NER predictions\n",
    "ner_results = ner_pipeline(ingredient_text)\n",
    "\n",
    "# Print results\n",
    "for entity in ner_results:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
